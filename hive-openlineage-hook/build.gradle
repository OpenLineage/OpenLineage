ext {
    openLineageVersion = '1.24.2'
    cloudDataLineageVersion = '0.46.0'
    producerClientVersion = '1.0.0'
    cloudStorageVersion = '2.45.0'
    gcsConnectorVersion = 'hadoop2-2.2.25'
    lombokVersion = '1.18.36'
    guavaVersion = '33.3.1-jre'
    bigqueryVersion = '2.44.0'
    hiveBigqueryConnectorVersion = '2.0.3'
    assertjVersion = '3.26.3'
    hiverunnerVersion = '6.1.0'
    jupiterVersion = '5.11.3'
    jacksonVersion = '2.18.1'
    mockitoVersion = '4.11.0'
    hiveVersion = '3.1.3'
    hadoopVersion = '2.10.2'
}

java {
    toolchain {
        languageVersion.set(JavaLanguageVersion.of(8))
    }
    sourceCompatibility = JavaVersion.VERSION_1_8
    targetCompatibility = JavaVersion.VERSION_1_8
}

compileJava {
    options.incremental = true
    options.compilerArgs << '-parameters'
    options.encoding = "UTF-8"
    sourceCompatibility = JavaVersion.VERSION_1_8
    targetCompatibility = JavaVersion.VERSION_1_8
}

compileTestJava {
    options.incremental = true
    options.compilerArgs << '-parameters'
    options.encoding = "UTF-8"
    sourceCompatibility = JavaVersion.VERSION_1_8
    targetCompatibility = JavaVersion.VERSION_1_8
}

// Testing ---------------------------------------------------------------------------------------

apply plugin: 'com.adarshr.test-logger'

testlogger {
    theme 'plain'
    showStandardStreams true
}


tasks.register('unitTest', Test) {
    useJUnitPlatform()
    filter {
        excludeTestsMatching "*acceptance*"
        excludeTestsMatching "*integration*"
    }
}

tasks.register('integrationTest', Test) {
    useJUnitPlatform()
    filter {
        includeTestsMatching "*integration*"
    }

    // Needed to run the integration without running out of memory
    forkEvery = 1
    maxParallelForks = 1
    maxHeapSize = "2g"
}

test {
    useJUnitPlatform()

    // Needed to run the integration without running out of memory
    forkEvery = 1
    maxParallelForks = 1
    maxHeapSize = "2g"

    // Use the `acceptanceTest` task instead of `test` for acceptance tests
    filter {
        excludeTestsMatching "*Acceptance*"
    }

    testLogging {
        events("passed", "skipped", "failed")
        showStandardStreams = true
    }
}

// Dependencies ----------------------------------------------------------------------------------

dependencies {
    compileOnly "org.projectlombok:lombok:${lombokVersion}"

    annotationProcessor "org.projectlombok:lombok:${lombokVersion}"
    compileOnly("org.apache.hadoop:hadoop-common:${hadoopVersion}") {
        exclude group: 'com.google.guava', module: 'guava'
        exclude group: 'org.apache.avro', module: 'avro'
    }

    compileOnly("org.apache.hive:hive-exec:${hiveVersion}") {
        exclude group: 'org.pentaho', module: '*'
        exclude group: 'org.apache.hadoop', module: '*'
    }


    implementation("com.google.guava:guava:${guavaVersion}")

    api ("io.openlineage:openlineage-java:${openLineageVersion}") {
        exclude group: 'com.fasterxml.jackson.core', module: '*'
    }
    implementation ("com.fasterxml.jackson.core:jackson-databind:${jacksonVersion}")

    // Test dependencies ---------------------------------------------------------------------
    testCompileOnly "org.projectlombok:lombok:${lombokVersion}"
    testAnnotationProcessor "org.projectlombok:lombok:${lombokVersion}"
    testImplementation "org.junit.jupiter:junit-jupiter:${jupiterVersion}"
    testImplementation("io.github.hiverunner:hiverunner:${hiverunnerVersion}") {
        exclude group: 'org.apache.tez', module: '*'
        exclude group: 'org.apache.hive', module: '*'
        exclude group: 'org.apache.hive.hcatalog', module: '*'
        exclude group: 'org.apache.hadoop', module: '*'
        exclude group: 'com.fasterxml.jackson.core', module: 'jackson-annotations'
        exclude group: 'org.junit.vintage', module: 'junit-vintage-engine'
    }
    testImplementation "org.assertj:assertj-core:${assertjVersion}"
    testImplementation ("com.google.cloud:google-cloud-bigquery:${bigqueryVersion}") {
        exclude group: 'io.grpc', module: '*'
        exclude group: 'com.google.protobuf', module: '*'
        exclude group: 'com.google.api', module: 'gax'
        exclude group: 'com.google.api', module: 'gax-grpc'
    }
    testImplementation ("com.google.cloud.hive:hive-bigquery-connector:${hiveBigqueryConnectorVersion}") {
        exclude module: 'hive-bigquery-parent'
        exclude group: 'com.google.protobuf', module: '*'
    }
    testImplementation("com.google.cloud:google-cloud-storage:${cloudStorageVersion}") {
        exclude group: 'io.grpc', module: '*'
        exclude group: 'com.google.protobuf', module: '*'
        exclude group: 'com.google.api', module: 'gax'
        exclude group: 'com.google.api', module: 'gax-grpc'
    }
    testImplementation("com.google.cloud.bigdataoss:gcs-connector:${gcsConnectorVersion}:shaded") {
        exclude group: 'io.grpc', module: '*'
        exclude group: 'com.google.guava', module: '*'
        exclude group: 'com.google.code.gson', module: '*'
        exclude group: 'com.google.protobuf', module: '*'
        exclude group: 'com.google.api', module: 'gax'
        exclude group: 'com.google.api', module: 'gax-grpc'
    }
    testImplementation ("io.openlineage:openlineage-java:${openLineageVersion}") {
        exclude group: 'com.fasterxml.jackson.core', module: '*'
    }
    testImplementation ("io.openlineage:transports-gcplineage:${openLineageVersion}")
    testImplementation "com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:${jacksonVersion}"
    testImplementation "com.google.cloud:google-cloud-datalineage:${cloudDataLineageVersion}"
    testImplementation "com.google.cloud.datalineage:producerclient-java8:${producerClientVersion}"
    testImplementation "org.mockito:mockito-core:${mockitoVersion}"
    testImplementation "org.mockito:mockito-junit-jupiter:${mockitoVersion}"

    // FIXME: Workaround for Datanucleus to work with the shaded-integration-test-dependencies library
    //  Fix it properly in the shaded-integration-test-dependencies's lib shading instead.
    testImplementation 'org.datanucleus:datanucleus-rdbms:4.1.19'
    testImplementation 'org.datanucleus:datanucleus-api-jdo:4.2.4'
    testImplementation 'org.datanucleus:datanucleus-core:4.1.17'

    testImplementation("org.apache.hive:hive-exec:${hiveVersion}") {
        exclude group: 'org.pentaho', module: '*'
        exclude group: 'org.apache.hadoop', module: '*'
    }
    testImplementation("org.apache.hive:hive-common:${hiveVersion}") {
        exclude group: 'org.apache.hadoop', module: '*'
        exclude group: 'com.github.joshelser', module: 'dropwizard-metrics-hadoop-metrics2-reporter'
    }
    testImplementation("org.apache.hive:hive-service:${hiveVersion}") {
        exclude group: 'org.pentaho', module: '*'
        exclude group: 'org.apache.hadoop', module: '*'
        exclude group: 'org.apache.hbase', module: '*'
        exclude group: 'org.apache.parquet', module: 'parquet-hadoop-bundle'
        exclude group: 'com.github.joshelser', module: 'dropwizard-metrics-hadoop-metrics2-reporter'
        exclude group: 'com.lmax', module: 'disruptor'
    }
    testImplementation("org.apache.hive.hcatalog:hive-hcatalog-pig-adapter:${hiveVersion}") {
        exclude group: 'org.apache.hive', module: 'hive-exec'
        exclude group: 'org.apache.hadoop', module: '*'
        exclude group: 'org.apache.pig', module: '*'
    }

    testImplementation("org.apache.hadoop:hadoop-common:${hadoopVersion}") {
        exclude group: 'com.google.guava', module: 'guava'
        exclude group: 'org.apache.avro', module: 'avro'
    }
    testImplementation("org.apache.hadoop:hadoop-mapreduce-client-common:${hadoopVersion}") {
        exclude group: 'com.google.guava', module: 'guava'
        exclude group: 'org.apache.avro', module: 'avro'
    }
    testImplementation("org.apache.hadoop:hadoop-hdfs:${hadoopVersion}") {
        exclude group: 'com.google.guava', module: 'guava'
    }

}

// Shading ---------------------------------------------------------------------------------------

apply plugin: 'com.gradleup.shadow'

shadowJar {
    archiveClassifier.set('shaded')
//    doFirst {
//        println "Files to be included in shadow jar:"
//        inputs.files.each { println it }
//    }

    zip64 true

    exclude 'module-info.class'
    exclude 'META-INF/*.SF'
    exclude 'META-INF/*.DSA'
    exclude 'META-INF/*.RSA'
    exclude 'META-INF/MANIFEST.MF'
    exclude 'META-INF/DEPENDENCIES'
    exclude 'META-INF/LICENSE'
    exclude 'META-INF/NOTICE'

    dependencies {
        exclude(dependency("com.google.guava:guava:${guavaVersion}"))
        exclude(dependency("com.fasterxml.jackson.core:jackson-databind:${jacksonVersion}"))
    }

    // Relocate some packages
//    [
//            'com.google.common',
//            'com.google.protobuf',
//            'com.google.longrunning',
//            'com.fasterxml',
//            'io.grpc',
//
//            // FIXME: Temporary to avoid conflicts with Dataproc's built-in
//            //  OpenLineage and related libraries
//            'io.openlineage.client',
//            'io.openlineage.core',
//            'io.openlineage.server',
//            'io.micrometer',
//            'com.google.cloud.datalineage',
//            'com.google.cloud.datacatalog',
//    ].each { pkg ->
//        relocate pkg, "hive.openlineage.repackaged.${pkg}"
//    }

    manifest {
        attributes([
                'Created-By'            : "Gradle ${gradle.gradleVersion}",
                'Built-By'              : System.getProperty('user.name'),
                'Build-Jdk'             : System.getProperty('java.version'),
                'Implementation-Title'  : project.name,
                'Implementation-Version': project.version
        ])
    }
    zip64 true
}

// Create the Version properties file ----------------------------------------------------

tasks.register('createVersionProperties') {
    doLast {
        File dir = new File("$projectDir/src/main/resources/io/openlineage/hive/client/")
        dir.mkdirs()
        new File("$projectDir/src/main/resources/io/openlineage/hive/client/version.properties").withWriter { w ->
            Properties p = new Properties()
            p['version'] = parent.project.version.toString()
            p.each { key, value ->
                w.write("$key=$value\n")
            }
        }
    }
}

processResources {
    dependsOn tasks.named('createVersionProperties')
}

classes {
    dependsOn processResources
}