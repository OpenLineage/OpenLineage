ext {
    openLineageVersion = '1.24.2'
    cloudDataLineageVersion = '0.46.0'
    producerClientVersion = '1.0.0'
    cloudStorageVersion = '2.45.0'
    gcsConnectorVersion = 'hadoop2-2.2.25'
    lombokVersion = '1.18.36'
    guavaVersion = '33.3.1-jre'
    bigqueryVersion = '2.44.0'
    hiveBigqueryConnectorVersion = '2.0.3'
    assertjVersion = '3.26.3'
    hiverunnerVersion = '6.1.0'
    jupiterVersion = '5.11.3'
    jacksonVersion = '2.18.1'
    mockitoVersion = '4.11.0'
}

java {
    toolchain {
        languageVersion.set(JavaLanguageVersion.of(8))
    }
    sourceCompatibility = JavaVersion.VERSION_1_8
    targetCompatibility = JavaVersion.VERSION_1_8
}

compileJava {
    options.incremental = true
    options.compilerArgs << '-parameters'
    options.encoding = "UTF-8"
    sourceCompatibility = JavaVersion.VERSION_1_8
    targetCompatibility = JavaVersion.VERSION_1_8
}

compileTestJava {
    options.incremental = true
    options.compilerArgs << '-parameters'
    options.encoding = "UTF-8"
    sourceCompatibility = JavaVersion.VERSION_1_8
    targetCompatibility = JavaVersion.VERSION_1_8
}

// Testing ---------------------------------------------------------------------------------------

apply plugin: 'com.adarshr.test-logger'

testlogger {
    theme 'plain'
    showStandardStreams true
}

tasks.register('acceptanceTest', Test) {
    useJUnitPlatform()

    filter {
        includeTestsMatching "*acceptance*"
    }

    // Create the shaded jar before an acceptance test is run.
    // The shaded JAR is later automatically uploaded to the test cluster
    // as part the acceptance test execution.
    dependsOn shadowJar
}

tasks.register('unitTest', Test) {
    useJUnitPlatform()
    filter {
        excludeTestsMatching "*acceptance*"
        excludeTestsMatching "*integration*"
    }
}

tasks.register('integrationTest', Test) {
    useJUnitPlatform()
    filter {
        includeTestsMatching "*integration*"
    }

    // Needed to run the integration without running out of memory
    forkEvery = 1
    maxParallelForks = 1
    maxHeapSize = "2g"
}

test {
    useJUnitPlatform()

    // Needed to run the integration without running out of memory
    forkEvery = 1
    maxParallelForks = 1
    maxHeapSize = "2g"

    // Use the `acceptanceTest` task instead of `test` for acceptance tests
    filter {
        excludeTestsMatching "*Acceptance*"
    }

    testLogging {
        events("passed", "skipped", "failed")
        showStandardStreams = true
    }
}

// Dependencies ----------------------------------------------------------------------------------

dependencies {
    annotationProcessor "org.projectlombok:lombok:${lombokVersion}"
    implementation "org.projectlombok:lombok:${lombokVersion}"
    implementation "com.google.guava:guava:${guavaVersion}"
    compileOnly project(path: ':shaded-integration-test-dependencies', configuration: 'shadow')
    implementation ("io.openlineage:openlineage-java:${openLineageVersion}") {
        exclude group: 'com.fasterxml.jackson.core', module: '*'
    }
    implementation "com.fasterxml.jackson.core:jackson-databind:${jacksonVersion}"
    // TODO: We might not want this to be included in the shaded JAR and instead rely on Dataproc including it?
    implementation ("io.openlineage:transports-gcplineage:${openLineageVersion}")
    implementation ("io.openlineage:transports-gcs:${openLineageVersion}")

    // Test dependencies ---------------------------------------------------------------------

    testImplementation project(path: ':shaded-integration-test-dependencies', configuration: 'shadow')
    testImplementation project(path: ':shaded-acceptance-test-dependencies', configuration: 'shadow')
    testAnnotationProcessor "org.projectlombok:lombok:${lombokVersion}"
    testImplementation "org.junit.jupiter:junit-jupiter:${jupiterVersion}"
    testImplementation("io.github.hiverunner:hiverunner:${hiverunnerVersion}") {
        exclude group: 'org.apache.tez', module: '*'
        exclude group: 'org.apache.hive', module: '*'
        exclude group: 'org.apache.hive.hcatalog', module: '*'
        exclude group: 'org.apache.hadoop', module: '*'
        exclude group: 'com.fasterxml.jackson.core', module: 'jackson-annotations'
        exclude group: 'org.junit.vintage', module: 'junit-vintage-engine'
    }
    testImplementation "org.assertj:assertj-core:${assertjVersion}"
    testImplementation ("com.google.cloud:google-cloud-bigquery:${bigqueryVersion}") {
        exclude group: 'io.grpc', module: '*'
        exclude group: 'com.google.protobuf', module: '*'
        exclude group: 'com.google.api', module: 'gax'
        exclude group: 'com.google.api', module: 'gax-grpc'
    }
    testImplementation ("com.google.cloud.hive:hive-bigquery-connector:${hiveBigqueryConnectorVersion}") {
        exclude module: 'hive-bigquery-parent'
        exclude group: 'com.google.protobuf', module: '*'
    }
    testImplementation("com.google.cloud:google-cloud-storage:${cloudStorageVersion}") {
        exclude group: 'io.grpc', module: '*'
        exclude group: 'com.google.protobuf', module: '*'
        exclude group: 'com.google.api', module: 'gax'
        exclude group: 'com.google.api', module: 'gax-grpc'
    }
    testImplementation("com.google.cloud.bigdataoss:gcs-connector:${gcsConnectorVersion}:shaded") {
        exclude group: 'io.grpc', module: '*'
        exclude group: 'com.google.guava', module: '*'
        exclude group: 'com.google.code.gson', module: '*'
        exclude group: 'com.google.protobuf', module: '*'
        exclude group: 'com.google.api', module: 'gax'
        exclude group: 'com.google.api', module: 'gax-grpc'
    }
    testImplementation ("io.openlineage:openlineage-java:${openLineageVersion}") {
        exclude group: 'com.fasterxml.jackson.core', module: '*'
    }
    testImplementation ("io.openlineage:transports-gcplineage:${openLineageVersion}")
    testImplementation "com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:${jacksonVersion}"
    testImplementation "com.google.cloud:google-cloud-datalineage:${cloudDataLineageVersion}"
    testImplementation "com.google.cloud.datalineage:producerclient-java8:${producerClientVersion}"
    testImplementation "org.mockito:mockito-core:${mockitoVersion}"
    testImplementation "org.mockito:mockito-junit-jupiter:${mockitoVersion}"

    // FIXME: Workaround for Datanucleus to work with the shaded-integration-test-dependencies library
    //  Fix it properly in the shaded-integration-test-dependencies's lib shading instead.
    testImplementation 'org.datanucleus:datanucleus-rdbms:4.1.19'
    testImplementation 'org.datanucleus:datanucleus-api-jdo:4.2.4'
    testImplementation 'org.datanucleus:datanucleus-core:4.1.17'
}

// Shading ---------------------------------------------------------------------------------------

apply plugin: 'com.gradleup.shadow'

shadowJar {
    archiveClassifier.set('shaded')
    doFirst {
        println "Files to be included in shadow jar:"
        inputs.files.each { println it }
    }

    zip64 true

    exclude 'module-info.class'
    exclude 'META-INF/*.SF'
    exclude 'META-INF/*.DSA'
    exclude 'META-INF/*.RSA'
    exclude 'META-INF/MANIFEST.MF'
    exclude 'META-INF/DEPENDENCIES'
    exclude 'META-INF/LICENSE'
    exclude 'META-INF/NOTICE'

    // Relocate some packages
    [
            'com.google.common',
            'com.google.protobuf',
            'com.google.longrunning',
            'com.fasterxml',
            'io.grpc',

            // FIXME: Temporary to avoid conflicts with Dataproc's built-in
            //  OpenLineage and related libraries
            'io.openlineage.client',
            'io.openlineage.core',
            'io.openlineage.server',
            'io.micrometer',
            'com.google.cloud.datalineage',
            'com.google.cloud.datacatalog',
    ].each { pkg ->
        relocate pkg, "hive.openlineage.repackaged.${pkg}"
    }

    mergeServiceFiles()
}

// Create the Version properties file ----------------------------------------------------

tasks.register('createVersionProperties') {
    doLast {
        File dir = new File("$projectDir/src/main/resources/io/openlineage/hive/client/")
        dir.mkdirs()
        new File("$projectDir/src/main/resources/io/openlineage/hive/client/version.properties").withWriter { w ->
            Properties p = new Properties()
            p['version'] = parent.project.version.toString()
            p.each { key, value ->
                w.write("$key=$value\n")
            }
        }
    }
}

processResources {
    dependsOn tasks.named('createVersionProperties')
}

classes {
    dependsOn processResources
}