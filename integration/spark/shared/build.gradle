import org.apache.tools.ant.filters.ReplaceTokens
import groovy.io.FileType

import java.nio.file.Files


plugins {
    id 'java'
    id 'java-library'
    id 'java-test-fixtures'
    id 'com.diffplug.spotless' version '6.12.0'
    id "com.github.johnrengelman.shadow" version "8.1.1"
    id "pmd"
}

pmd {
    consoleOutput = true
    toolVersion = "6.46.0"
    rulesMinimumPriority = 5
    ruleSetFiles = rootProject.files("pmd-openlineage.xml")
    ruleSets = []
    ignoreFailures = true
}

pmdMain {
    dependsOn shadowJar
    reports {
        html.required = true
    }
}

pmdTest {
    dependsOn shadowJar
}

archivesBaseName='openlineage-spark-shared'


repositories {
    mavenLocal()
    mavenCentral()
    maven {
        url = 'https://astronomer.jfrog.io/artifactory/maven-public-libs-snapshot'
    }
}

configurations {
    lombok
}

ext {
    assertjVersion = '3.25.1'
    bigqueryVersion = '0.29.0'
    junit5Version = '5.10.1'
    sparkVersion = '3.2.2'
    sparkVersionShort = '3.2'
    scalaVersion = project.getProperty('scala.binary.version')
    snowflakeVersion = '2.11.0'
    postgresqlVersion = '42.7.1'
    mockitoVersion = '4.11.0'
    testcontainersVersion = '1.19.3'
}

dependencies {
    api "io.openlineage:openlineage-java:${project.version}"
    api "io.openlineage:openlineage-sql-java:${project.version}"

    compileOnly "org.apache.spark:spark-core_${scalaVersion}:${sparkVersion}"
    compileOnly "org.apache.spark:spark-sql_${scalaVersion}:${sparkVersion}"
    compileOnly ("com.google.cloud.spark:spark-bigquery-with-dependencies_${scalaVersion}:${bigqueryVersion}") {
        exclude group: 'com.fasterxml.jackson.core'
        exclude group: 'com.fasterxml.jackson.module'
    }
    compileOnly ("net.snowflake:spark-snowflake_${scalaVersion}:${snowflakeVersion}-spark_${sparkVersionShort}") {
        exclude group: 'com.google.guava:guava'
        exclude group: "org.apache.spark:spark-core_${scalaVersion}"
        exclude group: "org.apache.spark:spark-sql_${scalaVersion}"
        exclude group: "org.apache.spark:spark-catalyst_${scalaVersion}"
    }

    compileOnly "org.apache.spark:spark-hive_${scalaVersion}:${sparkVersion}"
    compileOnly "org.apache.spark:spark-sql-kafka-0-10_${scalaVersion}:${sparkVersion}"
    compileOnly ("com.databricks:databricks-dbutils-scala_${scalaVersion}:0.1.4") {
        exclude group: 'com.fasterxml.jackson.core'
    }

    // TODO: those fixtures should be cleaned in future PRs -> integration tests got moved to app
    testFixturesApi platform('org.junit:junit-bom:5.10.1')
    testFixturesApi "org.junit.jupiter:junit-jupiter:${junit5Version}"
    testFixturesApi "org.junit.jupiter:junit-jupiter-params:${junit5Version}"

    testFixturesApi "org.postgresql:postgresql:${postgresqlVersion}"
    testFixturesApi 'org.hamcrest:hamcrest-library:2.2'
    testFixturesApi 'org.xerial:sqlite-jdbc:3.44.1.0'
    testFixturesApi "org.testcontainers:junit-jupiter:${testcontainersVersion}"
    testFixturesApi "org.testcontainers:postgresql:${testcontainersVersion}"
    testFixturesApi "org.testcontainers:mockserver:${testcontainersVersion}"
    testFixturesApi "org.testcontainers:kafka:${testcontainersVersion}"
    testFixturesApi "org.apache.kafka:kafka-clients:3.6.1"
    testFixturesApi('org.mock-server:mockserver-client-java:5.14.0') {
        exclude group: 'com.google.guava', module: 'guava'
        exclude group: 'com.fasterxml.jackson.core'
        exclude group: 'com.fasterxml.jackson.datatype'
        exclude group: 'com.fasterxml.jackson.dataformat'
    }
    testFixturesApi group: 'org.awaitility', name: 'awaitility', version: '4.2.0'
    testFixturesApi "org.assertj:assertj-core:${assertjVersion}"
    testFixturesApi "org.mockito:mockito-core:${mockitoVersion}"
    testFixturesApi "org.mockito:mockito-inline:${mockitoVersion}"
    testFixturesApi "org.mockito:mockito-junit-jupiter:${mockitoVersion}"

    testImplementation "org.apache.spark:spark-core_${scalaVersion}:${sparkVersion}"
    testImplementation "org.apache.spark:spark-sql_${scalaVersion}:${sparkVersion}"
    testImplementation "org.apache.spark:spark-hive_${scalaVersion}:${sparkVersion}"
    testImplementation "com.google.cloud.spark:spark-bigquery-with-dependencies_${scalaVersion}:${bigqueryVersion}"
}

def commonTestConfiguration = {
    forkEvery 1
    maxParallelForks 5
    testLogging {
        events "passed", "skipped", "failed"
        showStandardStreams = true
    }
    systemProperties = [
            'junit.platform.output.capture.stdout': 'true',
            'junit.platform.output.capture.stderr': 'true',
            'spark.version'                       : "${sparkVersion}",
            'openlineage.spark.jar'               : "${archivesBaseName}-${project.version}.jar",
            'kafka.package.version'               : "org.apache.spark:spark-sql-kafka-0-10_${scalaVersion}:${sparkVersion}",
            'mockserver.logLevel'                 : 'ERROR'
    ]

    classpath = project.sourceSets.test.runtimeClasspath
}


test {
    dependsOn shadowJar
    configure commonTestConfiguration
    useJUnitPlatform {
        excludeTags 'integration-test'
    }
}

assemble {
    dependsOn shadowJar
}

shadowJar {
    minimize()
    archiveClassifier = ''
    zip64 true
}

spotless {
    def disallowWildcardImports = {
        String text = it
        def regex = ~/import .*\.\*;/
        def m = regex.matcher(text)
        if (m.find()) {
            throw new AssertionError("Wildcard imports disallowed - ${m.findAll()}")
        }
    }
    java {
        googleJavaFormat()
        removeUnusedImports()
        custom 'disallowWildcardImports', disallowWildcardImports
    }
}