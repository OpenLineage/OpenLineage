version: 2.1

orbs:
  gcp-cli: circleci/gcp-cli@2.2.0

checkout_project_root: &checkout_project_root
  # Override checkout path to project root (see: https://circleci.com/docs/2.0/configuration-reference/#checkout)
  checkout:
    path: ~/openlineage

install_python_client: &install_python_client
  run: (cd ~/openlineage/client/python && pip install . --user)

install_integration_common: &install_integration_common
  run: (cd ~/openlineage/integration/common && pip install . --user)

only_on_main: &only_on_main
  filters:
    branches:
      only: main

# Only trigger CI job on release (=X.Y.Z) with possible (rcX)
only_on_release: &only_on_release
  filters:
    tags:
      only: /^[0-9]+(\.[0-9]+){2}(-rc\.[0-9]+)?$/
    branches:
      ignore: /.*/

param_build_tag: &param_build_tag
    parameters:
      build_tag:
        default: ""
        type: string

jobs:
  unit-test-client-python:
    working_directory: ~/openlineage/client/python
    docker:
      - image: circleci/python:3.6
    steps:
      - *checkout_project_root
      - run: pip install -e .[dev]
      - run: python -m flake8 --extend-ignore=F401
      - run: python -m pytest --cov=openlineage tests/
      - run: bash <(curl -s https://codecov.io/bash)

  build-client-python:
    working_directory: ~/openlineage/client/python
    docker:
      - image: circleci/python:3.6
    parameters:
      build_tag:
        default: ""
        type: string
    steps:
      - *checkout_project_root
      - run: python setup.py egg_info -b "<< parameters.build_tag >>" sdist bdist_wheel
      - persist_to_workspace:
          root: .
          paths:
            - ./dist/*.tar.gz
            - ./dist/*.whl

  build-client-java:
    working_directory: ~/openlineage/client/java
    docker:
      - image: cimg/openjdk:11.0
    steps:
      - *checkout_project_root
      - restore_cache:
          keys:
            - v1-client-java-{{ .Branch }}-{{ .Revision }}
            - v1-client-java-{{ .Branch }}
      - run: ./gradlew --no-daemon --stacktrace build
      - run: ./gradlew --no-daemon jacocoTestReport
      - run: bash <(curl -s https://codecov.io/bash)
      - store_test_results:
          path: client/java/build/test-results/test
      - store_artifacts:
          path: build/reports/tests/test
          destination: test-report
      - save_cache:
          key: v1-client-java-{{ .Branch }}-{{ .Revision }}
          paths:
            - ~/.gradle

  release-client-java:
    working_directory: ~/openlineage/client/java
    docker:
      - image: cimg/openjdk:11.0
    steps:
      - *checkout_project_root
      - run: |
          # Get, then decode the GPG private key used to sign *.jar
          export ORG_GRADLE_PROJECT_signingKey=$(echo $GPG_SIGNING_KEY | base64 -d)
          export RELEASE_PASSWORD=$(echo $SONATYPE_PASSWORD)
          export RELEASE_USERNAME=$(echo $SONATYPE_USER)

          # publish jar to maven local so it can be found by dependents
          ./gradlew publishToMavenLocal

          # Publish *.jar
          ./gradlew publish
      - save_cache:
          key: v1-release-client-java-{{ .Branch }}-{{ .Revision }}
          paths:
            - ~/.m2

  publish-snapshot-client-java:
    working_directory: ~/openlineage/client/java
    docker:
      - image: cimg/openjdk:11.0
    steps:
      - *checkout_project_root
      - run: |
          # Get, then decode the GPG private key used to sign *.jar
          export ORG_GRADLE_PROJECT_signingKey=$(echo $GPG_SIGNING_KEY | base64 -d)
          export RELEASE_PASSWORD=$(echo $ARTIFACTORY_PASSWORD)
          export RELEASE_USERNAME=$(echo $ARTIFACTORY_USERNAME)
          # Publish *.jar
          ./gradlew publish

  release-integration-spark:
    working_directory: ~/openlineage/integration/spark
    docker:
      - image: circleci/openjdk:8-jdk
    steps:
      - *checkout_project_root
      - restore_cache:
          keys:
            - v1-release-client-java-{{ .Branch }}-{{ .Revision }}
            - v1-release-client-java-{{ .Branch }}
      - run: |
          cd ../../client/java
          ./gradlew  --no-daemon publishToMavenLocal
          cd -
          # Get, then decode the GPG private key used to sign *.jar
          export ORG_GRADLE_PROJECT_signingKey=$(echo $GPG_SIGNING_KEY | base64 -d)
          export RELEASE_PASSWORD=$(echo $SONATYPE_PASSWORD)
          export RELEASE_USERNAME=$(echo $SONATYPE_USER)
          # Publish *.jar
          ./gradlew publish

  publish-snapshot-integration-spark:
    working_directory: ~/openlineage/integration/spark
    docker:
      - image: circleci/openjdk:8-jdk
    steps:
      - *checkout_project_root
      - run: |
          # Get, then decode the GPG private key used to sign *.jar
          export ORG_GRADLE_PROJECT_signingKey=$(echo $GPG_SIGNING_KEY | base64 -d)
          export RELEASE_PASSWORD=$(echo $ARTIFACTORY_PASSWORD)
          export RELEASE_USERNAME=$(echo $ARTIFACTORY_USERNAME)
          # Publish *.jar
          ./gradlew publish

  build-integration-spark:
    parameters:
      spark-version:
        type: string
    working_directory: ~/openlineage/integration/spark
    docker:
      - image: circleci/openjdk:8-jdk
    steps:
      - *checkout_project_root
      - restore_cache:
          keys:
            - v1-integration-spark-{{ .Branch }}-{{ .Revision }}
            - v1-integration-spark-{{ .Branch }}
      - attach_workspace:
          at: .
      - run: (cd ./../../client/java/ && ./gradlew --no-daemon --stacktrace publishToMavenLocal)
      - run: ./gradlew --no-daemon --stacktrace build -Pspark.version=<< parameters.spark-version >>
      - run:
          when: on_fail
          command: cat integration/spark/build/test-results/test/TEST-*.xml
      - run: ./gradlew --no-daemon jacocoTestReport
      - store_test_results:
          path: integration/spark/build/test-results/test
      - store_artifacts:
          path: build/reports/tests/test
          destination: test-report
      - save_cache:
          key: v1-integration-spark-{{ .Branch }}-{{ .Revision }}
          paths:
            - ~/.gradle

  unit-test-integration-common:
    working_directory: ~/openlineage/integration/common
    docker:
      - image: circleci/python:3.6
    steps:
      - *checkout_project_root
      - *install_python_client
      - run: pip install -e .[dev]
      - run: flake8
      - run: pytest --cov=openlineage tests/
      - run: bash <(curl -s https://codecov.io/bash)

  build-integration-common:
    working_directory: ~/openlineage/integration/common
    docker:
      - image: circleci/python:3.6
    <<: *param_build_tag
    steps:
      - *checkout_project_root
      - run: python setup.py egg_info -b "<< parameters.build_tag >>" sdist bdist_wheel
      - persist_to_workspace:
          root: .
          paths:
            - ./dist/*.whl
            - ./dist/*.tar.gz

  build-integration-dbt:
    working_directory: ~/openlineage/integration/dbt
    docker:
      - image: circleci/python:3.6
    <<: *param_build_tag
    steps:
      - *checkout_project_root
      - run: python setup.py egg_info -b "<< parameters.build_tag >>" sdist bdist_wheel
      - persist_to_workspace:
          root: .
          paths:
            - ./dist/*.whl
            - ./dist/*.tar.gz

  integration-test-integration-spark:
    parameters:
      spark-version:
        type: string
    working_directory: ~/openlineage/integration/spark
    machine: true
    environment:
      TESTCONTAINERS_RYUK_DISABLED: "true"
      JDK8_HOME: /usr/lib/jvm/java-8-openjdk-amd64
    steps:
      - *checkout_project_root
      - restore_cache:
          keys:
            - v1-integration-spark-{{ .Branch }}-{{ .Revision }}
            - v1-integration-spark-{{ .Branch }}
      - run: (cd ./../../client/java/ && ./gradlew --no-daemon --stacktrace publishToMavenLocal)
      - run: ./gradlew --no-daemon --stacktrace integrationTest -Pspark.version=<< parameters.spark-version >>
      - run:
          when: on_fail
          command: cat integration/spark/build/test-results/integrationTest/TEST-*.xml
      - run: ./gradlew --no-daemon jacocoTestReport
      - store_test_results:
          path: integration/spark/build/test-results/integrationTest
      - store_artifacts:
          path: integration/spark/build/reports/tests/integrationTest
          destination: test-report
      - save_cache:
          key: v1-integration-spark-{{ .Branch }}-{{ .Revision }}
          paths:
            - ~/.gradle

  unit-test-integration-airflow-1:
    working_directory: ~/openlineage/integration/airflow
    docker:
      - image: circleci/python:3.6
    steps:
      - *checkout_project_root
      - *install_python_client
      - *install_integration_common
      - run: pip install --upgrade pip==20.2.4
      - run: pip install -e .[dev,airflow-1] --constraint="https://raw.githubusercontent.com/apache/airflow/constraints-1.10.15/constraints-3.6.txt"
      - run: flake8 --exclude integration
      - run: airflow initdb
      - run: pytest --cov=openlineage --ignore tests/integration tests/
      - run: bash <(curl -s https://codecov.io/bash)


  unit-test-integration-airflow-2:
    working_directory: ~/openlineage/integration/airflow
    docker:
      - image: circleci/python:3.6
    steps:
      - *checkout_project_root
      - *install_python_client
      - *install_integration_common
      - run: pip install -e .[dev,airflow-2] --constraint="https://raw.githubusercontent.com/apache/airflow/constraints-2.1.3/constraints-3.6.txt"
      - run: flake8 --exclude integration
      - run: airflow db init
      - run: pytest --cov=openlineage --ignore tests/integration --ignore tests/test_openlineage_dag.py tests/
      - run: bash <(curl -s https://codecov.io/bash)

  build-integration-airflow:
    working_directory: ~/openlineage/integration/airflow
    docker:
      - image: circleci/python:3.6
    <<: *param_build_tag
    steps:
      - *checkout_project_root
      - *install_python_client
      - *install_integration_common
      - run: python setup.py egg_info -b "<< parameters.build_tag >>" sdist bdist_wheel
      - persist_to_workspace:
          root: .
          paths:
            - ./dist/*.whl
            - ./dist/*.tar.gz

  integration-test-integration-airflow:
    working_directory: ~/openlineage/integration/
    machine: true
    steps:
      - *checkout_project_root
      - gcp-cli/install
      - gcp-cli/initialize
      - run: ../.circleci/get-docker-compose.sh
      - run: cp -r ../client/python python
      - run: docker build -f airflow/Dockerfile.tests -t openlineage-airflow-base .
      - run: ./airflow/tests/integration/docker/up.sh

  integration-test-integration-airflow-2:
    working_directory: ~/openlineage/integration/
    machine: true
    steps:
      - *checkout_project_root
      - gcp-cli/install
      - gcp-cli/initialize
      - run: ../.circleci/get-docker-compose.sh
      - run: cp -r ../client/python python
      - run: docker build -f airflow/Dockerfile.tests -t openlineage-airflow-base .
      - run: ./airflow/tests/integration/docker/up-2.sh


  publish-snapshot-python:
    working_directory: ~/openlineage
    docker:
      - image: circleci/python:3.6
    steps:
      - *checkout_project_root
      - attach_workspace:
          at: .
      - run: pip install wheel twine
      - run: python -m twine upload --non-interactive --verbose -u $ARTIFACTORY_USERNAME -p $ARTIFACTORY_PASSWORD --repository-url https://datakin.jfrog.io/artifactory/api/pypi/pypi-public-libs-release dist/*

  release-python:
    working_directory: ~/openlineage
    docker:
      - image: circleci/python:3.6
    steps:
      - *checkout_project_root
      - attach_workspace:
          at: .
      - run: pip install wheel twine
      - run: python -m twine upload --non-interactive --verbose --repository pypi dist/*

  publish-spec:
    working_directory: ~/openlineage
    docker:
      - image: cimg/base:2021.07
    steps:
      - *checkout_project_root
      - add_ssh_keys:
          fingerprints:
            - "1c:d1:da:e8:76:d7:f7:04:31:07:18:fd:55:ca:e1:2e"
      - run: spec/release.sh


workflows:
  openlineage:
    jobs:
      - build-client-java
      - publish-snapshot-client-java:
          <<: *only_on_main
          context: release
          requires:
            - build-client-java
      - build-integration-spark:
          matrix:
            parameters:
              spark-version: [ '2.4.1', '3.1' ]
      - integration-test-integration-spark:
          matrix:
            parameters:
              spark-version: [ '2.4.1', '3.1' ]
          requires:
            - build-integration-spark
      - publish-snapshot-integration-spark:
          <<: *only_on_main
          context: release
          requires:
            - integration-test-integration-spark
      - unit-test-client-python
      - build-client-python:
          <<: *only_on_main
          build_tag: ".dev<< pipeline.number >>"
          requires:
            - unit-test-client-python
      - unit-test-integration-common
      - build-integration-common:
          <<: *only_on_main
          build_tag: ".dev<< pipeline.number >>"
          requires:
            - unit-test-integration-common
      - unit-test-integration-airflow-1
      - unit-test-integration-airflow-2
      - integration-test-integration-airflow:
          context: integration-tests
          requires:
            - unit-test-integration-airflow-1
            - unit-test-integration-common
            - unit-test-client-python
          filters:
            branches:
              ignore: /pull\/[0-9]+/
      - integration-test-integration-airflow-2:
          context: integration-tests
          requires:
            - unit-test-integration-airflow-2
            - unit-test-integration-common
            - unit-test-client-python
          filters:
            branches:
              ignore: /pull\/[0-9]+/
      - build-integration-airflow:
          <<: *only_on_main
          build_tag: ".dev<< pipeline.number >>"
          requires:
            - integration-test-integration-airflow
      - build-integration-dbt:
          <<: *only_on_main
          build_tag: ".dev<< pipeline.number >>"
      - publish-snapshot-python:
          <<: *only_on_main
          context: release
          requires:
            - build-client-python
            - build-integration-common
            - build-integration-airflow
            - build-integration-dbt
      - publish-spec:
          <<: *only_on_main
          context: release
  release:
    jobs:
      - release-client-java:
          <<: *only_on_release
          context: release
      - release-integration-spark:
          <<: *only_on_release
          context: release
          requires:
            - release-client-java
      - build-client-python:
          <<: *only_on_release
      - build-integration-common:
          <<: *only_on_release
      - build-integration-airflow:
          <<: *only_on_release
      - build-integration-dbt:
          <<: *only_on_release
      - release-python:
          <<: *only_on_release
          context: release
          requires:
            - build-client-python
            - build-integration-common
            - build-integration-airflow
            - build-integration-dbt
