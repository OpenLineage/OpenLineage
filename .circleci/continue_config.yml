version: 2.1

orbs:
  gcp-cli: circleci/gcp-cli@2.2.0
  rust: circleci/rust@1.6.0
  slack: circleci/slack@4.13.3

parameters:
  build-context:
    default: "pr"
    type: string
  databricks-test:
    type: string
    default: "disabled"
  nightly-run:
    type: string
    default: "inactive"

checkout_project_root: &checkout_project_root
  # Override checkout path to project root (see: https://circleci.com/docs/2.0/configuration-reference/#checkout)
  checkout:
    path: ~/openlineage

install_python_client: &install_python_client
  run: (cd ~/openlineage/client/python && pip install . --user)

commands:
  publish_shadow_jar_local:
    description: "Build shadow JAR and publish to maven local repo"
    steps:
      - run: ./gradlew --console=plain javadoc sourceJar shadowJar
      - run: |
          # Get, then decode the GPG private key used to sign *.jar
          export ORG_GRADLE_PROJECT_signingKey=$(echo $GPG_SIGNING_KEY | base64 -d)
          export RELEASE_PASSWORD=$(echo $OSSRH_TOKEN_PASSWORD)
          export RELEASE_USERNAME=$(echo $OSSRH_TOKEN_USERNAME)

          ./gradlew --console=plain publishToMavenLocal --info
  publish_shadow_jar:
    description: "Build shadow JAR and publish to maven public repo"
    steps:
      - run: ./gradlew --console=plain javadoc sourceJar shadowJar
      - run: |
          # Get, then decode the GPG private key used to sign *.jar
          export ORG_GRADLE_PROJECT_signingKey=$(echo $GPG_SIGNING_KEY | base64 -d)
          export RELEASE_PASSWORD=$(echo $OSSRH_TOKEN_PASSWORD)
          export RELEASE_USERNAME=$(echo $OSSRH_TOKEN_USERNAME)

          ./gradlew --console=plain publishToSonatype closeSonatypeStagingRepository --info
  set_java_17:
    description: Set Java to Java 17
    steps:
      - run:
          name: Java version Variable
          command: |
            JAVA=17

            JAVA8_HOME='/usr/lib/jvm/java-8-openjdk-amd64'
            JAVA17_HOME='/usr/lib/jvm/java-17-openjdk-amd64'
            
            JAVA_BIN="$JAVA17_HOME/bin/java"
            JAVAC_BIN="$JAVA17_HOME/bin/javac"
            echo 'export JAVA8_HOME=/usr/lib/jvm/java-8-openjdk-amd64' >> "$BASH_ENV"
            echo 'export JAVA17_HOME=/usr/lib/jvm/java-17-openjdk-amd64' >> "$BASH_ENV"
            echo 'export JAVA_BIN='$([ "$JAVA" = "17" ] && echo "$JAVA17_HOME/bin/java" || echo "$JAVA8_HOME/jre/bin/java") >> "$BASH_ENV"
            echo 'export JAVAC_BIN='$([ "$JAVA" = "17" ] && echo "$JAVA17_HOME/bin/javac" || echo "$JAVA8_HOME/bin/javac") >> "$BASH_ENV"
            echo "${JAVA}"
            echo "${JAVA_BIN}"
            echo "${JAVAC_BIN}"
            echo "Setting default Java to ${JAVA_BIN}"
            sudo update-alternatives --set java ${JAVA_BIN}
            sudo update-alternatives --set javac ${JAVAC_BIN}


  install_integration_common:
    description: "Install common integration"
    parameters:
      install_parser:
        type: boolean
        description: "Whether to install Rust SQL parser"
    steps:
      - attach_workspace:
          at: .
      - when:
          condition: << parameters.install_parser >>
          steps:
            - run: pip install target/wheels/*manylinux_2_17_x86_64*.whl
      - run: (cd ~/openlineage/integration/common && pip install . --user)


jobs:

  # SQL
  build-integration-sql-python:
    parameters:
      image:
        type: string
      resource_class:
        type: string
      run_tests:
        type: boolean
    working_directory: ~/openlineage/integration/sql
    machine:
      image: ubuntu-2404:current
    resource_class: << parameters.resource_class >>
    steps:
      - *checkout_project_root
      - run: docker run -it -v $PWD:/code << parameters.image >> bash -c 'cd /code; RUN_TESTS=<<parameters.run_tests>> bash iface-py/script/build.sh'
      - persist_to_workspace:
          root: ./iface-py
          paths:
            - ./target/wheels/*.whl
      - when:
          condition:
            equal: [ "quay.io/pypa/manylinux2014_x86_64", << parameters.image >> ]
          steps:
            - persist_to_workspace:
                root: ./iface-py
                paths:
                  - ./target/wheels/*.tar.gz
      - store_artifacts:
          path: ./iface-py/target/wheels
          destination: sql-artifacts


  build-integration-sql-python-macos:
    working_directory: ~/openlineage/integration/sql
    macos:
      xcode: 14.2.0
    resource_class: macos.m1.medium.gen1
    steps:
      - *checkout_project_root
      - run: RUN_TESTS=true bash iface-py/script/setup-macos.sh
      - run: RUN_TESTS=true bash iface-py/script/build-macos.sh
      - persist_to_workspace:
          root: ./iface-py
          paths:
            - target/wheels/*.whl
      - store_artifacts:
          path: ./iface-py/target/wheels
          destination: sql-artifacts-macos

  compile-integration-sql-java-linux:
    parameters:
      image:
        type: string
      resource_class:
        type: string
    working_directory: ~/openlineage/integration/sql
    machine:
      image: ubuntu-2404:current
    resource_class: << parameters.resource_class >>
    steps:
      - *checkout_project_root
      - run: docker run -it -v $PWD:/code << parameters.image >> bash -c 'cd /code/iface-java && bash script/compile.sh'
      - persist_to_workspace:
          root: ~/
          paths:
            - openlineage/integration/sql/target/debug/*.so
      - store_artifacts:
          path: ./target/debug/
          destination: sql-linux-artifacts

  compile-integration-sql-java-macos:
    parameters:
      resource_class:
        type: string
        default: "macos.m1.medium.gen1"
    working_directory: ~/openlineage/integration/sql/iface-java
    macos:
      xcode: 14.2.0
    resource_class: << parameters.resource_class >>
    steps:
      - *checkout_project_root
      - run: bash script/compile.sh
      - persist_to_workspace:
          root: ~/
          paths:
            - openlineage/integration/sql/target/debug/*.dylib
      - store_artifacts:
          path: ../target/debug/*.dylib
          destination: sql-macos-artifacts

  build-integration-sql-java:
    working_directory: ~/openlineage/integration/sql/iface-java
    docker:
      - image: cimg/openjdk:17.0
    resource_class: "medium"
    steps:
      - *checkout_project_root
      - attach_workspace:
          at: ~/
      - run: bash script/build.sh
      - persist_to_workspace:
          root: ~/
          paths:
            - .m2/repository/io/openlineage/openlineage-sql-java
            - openlineage/integration/sql/iface-java/build-cache
            - openlineage/integration/sql/iface-java/build
      - store_artifacts:
          path: ./build/libs
          destination: sql-java-artifacts

  release-integration-sql-java:
    working_directory: ~/openlineage/integration/sql/iface-java
    docker:
      - image: cimg/openjdk:17.0
    steps:
      - *checkout_project_root
      - attach_workspace:
          at: ~/
      # TODO: When moving to GH Actions, this should reuse jar build in
      # build-integration-sql-java rather than rebuild it.
      - run: bash script/build.sh
      - publish_shadow_jar

  # PYTHON
  unit-test-client-python:
    working_directory: ~/openlineage/client/python
    parameters:
      tox_env:
        type: string
      py_env:
        type: string
    docker:
      - image: cimg/python:<< parameters.py_env >>
    steps:
      - *checkout_project_root
      - run: python -m pip install tox uv
      - run: python -m tox r -e "<< parameters.tox_env >>" --notest
      - run: python -m tox r -e "<< parameters.tox_env >>" --skip-pkg-install

  unit-tests-client-python:
    working_directory: ~/openlineage/client/python
    docker:
      - image: cimg/python:3.11
    steps:
      - run: echo "All Python tests done"

  build-client-python:
    working_directory: ~/openlineage/client/python
    docker:
      - image: cimg/python:3.8
    steps:
      - *checkout_project_root
      - run: python -m pip install build
      - run: python -m build .
      - persist_to_workspace:
          root: .
          paths:
            - ./dist/*.tar.gz
            - ./dist/*.whl

  unit-test-integration-common:
    working_directory: ~/openlineage/integration/common
    docker:
      - image: cimg/python:3.8
    steps:
      - *checkout_project_root
      - attach_workspace:
          at: .
      - run: pip install uv tox==4.12.1
      - run: tox
      - run: bash <(curl -s https://codecov.io/bash)
      - store_test_results:
          path: test-results

  build-integration-dbt:
    working_directory: ~/openlineage/integration/dbt
    docker:
      - image: cimg/python:3.8
    steps:
      - *checkout_project_root
      - run: python setup.py sdist bdist_wheel
      - persist_to_workspace:
          root: .
          paths:
            - ./dist/*.whl
            - ./dist/*.tar.gz

  build-integration-common:
    working_directory: ~/openlineage/integration/common
    docker:
      - image: cimg/python:3.8
    steps:
      - *checkout_project_root
      - run: python setup.py sdist bdist_wheel
      - persist_to_workspace:
          root: .
          paths:
            - ./dist/*.whl
            - ./dist/*.tar.gz

  unit-test-integration-airflow:
    parameters:
      install_parser:
        type: boolean
      airflow-version:
        type: string
    working_directory: ~/openlineage/integration/airflow
    docker:
      - image: cimg/python:3.8
    steps:
      - *checkout_project_root
      - *install_python_client
      - install_integration_common:
          install_parser: << parameters.install_parser >>
      - run: pip install tox==3.27.1 mypy==0.971
      - run: python -m mypy --install-types --non-interactive --ignore-missing-imports openlineage
      - run: tox -e py3-<< parameters.airflow-version >>
      - store_test_results:
          path: test-results
      - run: bash <(curl -s https://codecov.io/bash)

  build-integration-airflow:
    working_directory: ~/openlineage/integration/airflow
    docker:
      - image: cimg/python:3.8
    steps:
      - *checkout_project_root
      - *install_python_client
      - install_integration_common:
          install_parser: true
      - run: python setup.py sdist bdist_wheel
      - persist_to_workspace:
          root: .
          paths:
            - ./dist/*.whl
            - ./dist/*.tar.gz

  integration-test-integration-airflow:
    parameters:
      airflow-image:
        type: string
    working_directory: ~/openlineage/integration/
    machine:
      image: ubuntu-2404:current
    resource_class: large
    steps:
      - *checkout_project_root
      - gcp-cli/install
      - gcp-cli/initialize
      - run: ../.circleci/get-docker-compose.sh
      - run: cp -r ../client/python python
      - attach_workspace:
          at: .
      - run: AIRFLOW_IMAGE=<< parameters.airflow-image >> ./airflow/tests/integration/docker/up.sh
      - store_artifacts:
          path: airflow/tests/integration/tests/airflow/logs
          destination: airflow-logs
          when: always
      - store_artifacts:
          path: airflow/tests/integration/tests/events
          destination: events
          when: always

  integration-test-integration-airflow-failure:
    parameters:
      failure-type:
        type: string
    working_directory: ~/openlineage/integration/
    machine:
      image: ubuntu-2404:current
    steps:
      - *checkout_project_root
      - run: ../.circleci/get-docker-compose.sh
      - run: cp -r ../client/python python
      - attach_workspace:
          at: .
      - run: AIRFLOW_IMAGE=apache/airflow:2.3.4-python3.8 ./airflow/tests/integration/docker/up-failure.sh << parameters.failure-type >>
      - store_artifacts:
          path: airflow/tests/integration/failures/airflow/logs
          destination: airflow-logs

  unit-test-integration-dagster:
    working_directory: ~/openlineage/integration/dagster
    docker:
      - image: cimg/python:3.8
    steps:
      - *checkout_project_root
      - *install_python_client
      - run: pip install -e .[dev]
      - run: python -m mypy --ignore-missing-imports --no-namespace-packages openlineage
      - run: pytest --cov=openlineage tests/
      - run: bash <(curl -s https://codecov.io/bash)

  build-integration-dagster:
    working_directory: ~/openlineage/integration/dagster
    docker:
      - image: cimg/python:3.8
    steps:
      - *checkout_project_root
      - *install_python_client
      - run: python setup.py sdist bdist_wheel
      - persist_to_workspace:
          root: .
          paths:
            - ./dist/*.whl
            - ./dist/*.tar.gz

  release-python:
    working_directory: ~/openlineage
    docker:
      - image: cimg/python:3.8
    steps:
      - *checkout_project_root
      - attach_workspace:
          at: .
      - run: pip install wheel twine
      - run: mkdir -p target/wheels && cp target/wheels/* dist/
      - run: |
          if [ -n "$CIRCLE_TAG" ]; then
            python -m twine upload --non-interactive --verbose --repository pypi dist/*
          else
            python -m twine check dist/*
          fi

  # JAVA
  build-client-java:
    working_directory: ~/openlineage/client/java
    parameters:
      release:
        default: false
        type: boolean
    docker:
      - image: cimg/openjdk:17.0
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - restore_cache:
          keys:
            - v1-client-java-{{ checksum "/tmp/checksum.txt" }}
      - run: ./gradlew --no-daemon --console=plain --stacktrace build check jacocoTestReport
      - run: bash <(curl -s https://codecov.io/bash)
      - publish_shadow_jar_local
      - persist_to_workspace:
          root: ~/
          paths:
            - .m2/repository/io/openlineage/openlineage-java
            - openlineage/client/java/build-cache
            - openlineage/client/java/build
      - store_test_results:
          path: client/java/build/test-results/test
      - store_artifacts:
          path: build/reports/tests/test
          destination: test-report
      - store_artifacts:
          path: build/reports/tests/pmd
          destination: pmd-report
      - store_artifacts:
          path: build/libs
          destination: libs
      - save_cache:
          key: v1-client-java-{{ checksum "/tmp/checksum.txt" }}
          paths:
            - ~/.gradle

  release-client-java:
    working_directory: ~/openlineage/client/java
    docker:
      - image: cimg/openjdk:17.0
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - attach_workspace:
          at: ~/
      - publish_shadow_jar
      - store_artifacts:
          path: ./build/libs
          destination: java-client-artifacts
      - save_cache:
          key: v1-release-client-java-{{ checksum "/tmp/checksum.txt" }}
          paths:
            - ~/.m2

  release-integration-spark:
    working_directory: ~/openlineage/integration/spark
    docker:
      - image: cimg/openjdk:17.0
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - restore_cache:
          keys:
            - v1-release-client-java-{{ checksum "/tmp/checksum.txt" }}
      - attach_workspace:
          at: ~/
      - run: |
          # Get, then decode the GPG private key used to sign *.jar
          export ORG_GRADLE_PROJECT_signingKey=$(echo $GPG_SIGNING_KEY | base64 -d)
          export RELEASE_PASSWORD=$(echo $OSSRH_TOKEN_PASSWORD)
          export RELEASE_USERNAME=$(echo $OSSRH_TOKEN_USERNAME)

          # Publish *.jar
          ./gradlew --no-daemon --console=plain clean publish --info -Pscala.binary.version=2.12 -Pjava.compile.home=/usr/local/jdk-17.0.11
          ./gradlew --no-daemon --console=plain clean publish --info -Pscala.binary.version=2.13 -Pjava.compile.home=/usr/local/jdk-17.0.11
      - store_artifacts:
          path: ./build/libs
          destination: spark-client-artifacts

  build-integration-spark:
    working_directory: ~/openlineage/integration/spark
    parameters:
      scala:
        type: string
      release:
        type: boolean
        default: false
    machine:
      image: ubuntu-2404:current
    resource_class: large
    environment:
      TESTCONTAINERS_RYUK_DISABLED: "true"
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - set_java_17
      - restore_cache:
          keys:
            - v1-integration-spark-{{ checksum "/tmp/checksum.txt" }}
      - attach_workspace:
          at: ~/
      - run: |
          # Get, then decode the GPG private key used to sign *.jar
          export ORG_GRADLE_PROJECT_signingKey=$(echo $GPG_SIGNING_KEY | base64 -d)
          export RELEASE_PASSWORD=$(echo $OSSRH_TOKEN_PASSWORD)
          export RELEASE_USERNAME=$(echo $OSSRH_TOKEN_USERNAME)
                  
          ./gradlew --console=plain javadoc sourceJar shadowJar -Pscala.binary.version=<< parameters.scala >> -Pjava.compile.home=/usr/lib/jvm/java-17-openjdk-amd64
          ./gradlew --console=plain publishToMavenLocal -Pscala.binary.version=<< parameters.scala >> -Pjava.compile.home=/usr/lib/jvm/java-17-openjdk-amd64
      - persist_to_workspace:
          root: ~/
          paths:
            - .m2/repository/io/openlineage/openlineage-spark_<< parameters.scala >>
            - openlineage/integration/spark/build-cache
            - openlineage/integration/spark/build/libs
      - store_artifacts:
          path: build/libs
          destination: libs
      - save_cache:
          key: v1-integration-spark-{{ checksum "/tmp/checksum.txt" }}
          paths:
            - ~/.gradle

  test-integration-spark:
    parameters:
      env-variant:
        type: string
    working_directory: ~/openlineage/integration/spark
    machine:
      image: ubuntu-2404:current
    resource_class: large
    environment:
      TESTCONTAINERS_RYUK_DISABLED: "true"
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - attach_workspace:
          at: ~/
      - run:
          name: Spark & Java version Variable
          command: |
            JAVA=$(echo << parameters.env-variant >> | cut -d '-' -f 1 | cut -d ':' -f 2)
            SPARK=$(echo << parameters.env-variant >> | cut -d '-' -f 2 | cut -d ':' -f 2)
            SCALA=$(echo << parameters.env-variant >> | cut -d '-' -f 3 | cut -d ':' -f 2)
            echo spark=$SPARK java=$JAVA scala=$SCALA
            JAVA8_HOME='/usr/lib/jvm/java-8-openjdk-amd64'
            JAVA17_HOME='/usr/lib/jvm/java-17-openjdk-amd64'
            
            echo 'export JAVA17_HOME=/usr/lib/jvm/java-17-openjdk-amd64' >> "$BASH_ENV"
            echo 'export SPARK='${SPARK} >> "$BASH_ENV"
            echo 'export JAVA_BIN='$([ "$JAVA" = "17" ] && echo "$JAVA17_HOME/bin/java" || echo "$JAVA8_HOME/jre/bin/java") >> "$BASH_ENV"
            echo 'export JAVAC_BIN='$([ "$JAVA" = "17" ] && echo "$JAVA17_HOME/bin/javac" || echo "$JAVA8_HOME/bin/javac") >> "$BASH_ENV"
            echo 'export SCALA='${SCALA} >> "$BASH_ENV"
            echo "${JAVA}"
            echo "${JAVA_BIN}"
            echo "${JAVAC_BIN}"
      - restore_cache:
          keys:
            - v1-integration-spark-{{ checksum "/tmp/checksum.txt" }}
      - run: |
          echo "Setting default Java to ${JAVA_BIN}"
          sudo update-alternatives --set java ${JAVA_BIN}
          sudo update-alternatives --set javac ${JAVAC_BIN}
      - run: ./gradlew --no-daemon --console=plain --stacktrace build check -Pspark.version=${SPARK} -Pscala.binary.version=${SCALA} -Pjava.compile.home=${JAVA17_HOME}
      - run:
          when: on_fail
          command: cat build/test-results/test/TEST-*.xml
      - run: ./gradlew --no-daemon --console=plain jacocoTestReport -Pscala.binary.version=${SCALA} -Pjava.compile.home=${JAVA17_HOME}
      - store_test_results:
          path: build/test-results/test
      - store_artifacts:
          path: build/reports/tests/test
          destination: test-report
      - store_artifacts:
          path: build/reports/tests/pmd
          destination: pmd-report

  integration-test-integration-spark:
    parameters:
      env-variant:
        type: string
    working_directory: ~/openlineage/integration/spark
    machine:
      image: ubuntu-2404:current
    resource_class: large
    environment:
      TESTCONTAINERS_RYUK_DISABLED: "true"
    steps:
      - *checkout_project_root
      - gcp-cli/install
      - gcp-cli/initialize
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - run:
          name: Spark & Java version Variable
          command: |
            JAVA=$(echo << parameters.env-variant >> | cut -d '-' -f 1 | cut -d ':' -f 2)
            SPARK=$(echo << parameters.env-variant >> | cut -d '-' -f 2 | cut -d ':' -f 2)
            SCALA=$(echo << parameters.env-variant >> | cut -d '-' -f 3 | cut -d ':' -f 2)
            echo spark=$SPARK java=$JAVA scala=$SCALA
            JAVA8_HOME='/usr/lib/jvm/java-8-openjdk-amd64'
            JAVA17_HOME='/usr/lib/jvm/java-17-openjdk-amd64'
            
            echo 'export JAVA17_HOME=/usr/lib/jvm/java-17-openjdk-amd64' >> "$BASH_ENV"
            echo 'export SPARK_VERSION_VAR='${SPARK} >> "$BASH_ENV"
            echo 'export SCALA='${SCALA} >> "$BASH_ENV"
            echo 'export JAVA_BIN='$([ "$JAVA" = "17" ] && echo "$JAVA17_HOME/bin/java" || echo "$JAVA8_HOME/jre/bin/java") >> "$BASH_ENV"
            echo 'export JAVAC_BIN='$([ "$JAVA" = "17" ] && echo "$JAVA17_HOME/bin/javac" || echo "$JAVA8_HOME/bin/javac") >> "$BASH_ENV"
            echo $JAVA_BIN
      - run: mkdir -p app/build/gcloud && echo $GCLOUD_SERVICE_KEY > app/build/gcloud/gcloud-service-key.json && chmod 644 app/build/gcloud/gcloud-service-key.json
      - restore_cache:
          keys:
            - v1-integration-spark-{{ checksum "/tmp/checksum.txt" }}
      - attach_workspace:
          at: ~/
      - run: |
          echo "Setting default Java to ${JAVA_BIN}"
          sudo update-alternatives --set java ${JAVA_BIN}
          sudo update-alternatives --set javac ${JAVAC_BIN}
      - run: ./gradlew --no-daemon --console=plain integrationTest -x test -Pspark.version=${SPARK_VERSION_VAR} -Pscala.binary.version=${SCALA} -Pjava.compile.home=${JAVA17_HOME}
      - run: ./gradlew --no-daemon --console=plain jacocoTestReport -Pscala.binary.version=${SCALA} -Pjava.compile.home=${JAVA17_HOME}
      - store_test_results:
          path: app/build/test-results/integrationTest
      - store_artifacts:
          path: app/build/reports/tests/integrationTest
          destination: test-report
      - save_cache:
          key: v1-integration-spark-{{ checksum "/tmp/checksum.txt" }}
          paths:
            - ~/.gradle

  build-integration-spark-extension-interfaces:
    parameters:
      release:
        type: boolean
        default: false
    working_directory: ~/openlineage/integration/spark-extension-interfaces
    docker:
      - image: cimg/openjdk:17.0
    resource_class: "medium"
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - attach_workspace:
          at: ~/
      - restore_cache:
          keys:
            - v1-spark-extension-interfaces-{{ checksum "/tmp/checksum.txt" }}
      - run: ./gradlew --no-daemon --console=plain --stacktrace build
      - run: ./gradlew --no-daemon --console=plain --info check
      - run: |
            # Get, then decode the GPG private key used to sign *.jar
            export ORG_GRADLE_PROJECT_signingKey=$(echo $GPG_SIGNING_KEY | base64 -d)
            export RELEASE_PASSWORD=$(echo $OSSRH_TOKEN_PASSWORD)
            export RELEASE_USERNAME=$(echo $OSSRH_TOKEN_USERNAME)

            ./gradlew --console=plain publishToMavenLocal --info
      - persist_to_workspace:
          root: ~/
          paths:
            - .m2/repository/io/openlineage/spark-extension-interfaces
            - openlineage/integration/spark-extension-interfaces/build-cache
            - openlineage/integration/spark-extension-interfaces/build
      - save_cache:
          key: v1-spark-extension-interfaces-{{ checksum "/tmp/checksum.txt" }}
          paths:
            - ~/.gradle

  build-integration-spark-extension-entrypoint:
    parameters:
      release:
        type: boolean
        default: false
    working_directory: ~/openlineage/integration/spark-extension-entrypoint
    docker:
      - image: cimg/openjdk:17.0
    resource_class: "medium"
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - attach_workspace:
          at: ~/
      - restore_cache:
          keys:
            - v1-spark-extension-entrypoint-{{ checksum "/tmp/checksum.txt" }}
      - run: ./gradlew --no-daemon --console=plain --stacktrace build
      - run: ./gradlew --no-daemon --console=plain --info check
      - persist_to_workspace:
          root: ~/
          paths:
            - .m2/repository/io/openlineage/spark-extension-entrypoint
            - openlineage/integration/spark-extension-entrypoint/build-cache
            - openlineage/integration/spark-extension-entrypoint/build
      - save_cache:
          key: v1-spark-extension-entrypoint-{{ checksum "/tmp/checksum.txt" }}
          paths:
            - ~/.gradle

  release-integration-spark-extension-interfaces:
    working_directory: ~/openlineage/integration/spark-extension-interfaces
    docker:
      - image: cimg/openjdk:17.0
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - attach_workspace:
          at: ~/
      - publish_shadow_jar
      - store_artifacts:
          path: ./build/libs
          destination: spark-extension-interfaces-artifacts
      - save_cache:
          key: v1-release-spark-extension-interfaces-{{ checksum "/tmp/checksum.txt" }}
          paths:
            - ~/.m2

  release-integration-spark-extension-entrypoint:
    working_directory: ~/openlineage/integration/spark-extension-entrypoint
    docker:
      - image: cimg/openjdk:17.0
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - attach_workspace:
          at: ~/
      - run: |
          # Get, then decode the GPG private key used to sign *.jar
          export ORG_GRADLE_PROJECT_signingKey=$(echo $GPG_SIGNING_KEY | base64 -d)
          export RELEASE_PASSWORD=$(echo $OSSRH_TOKEN_PASSWORD)
          export RELEASE_USERNAME=$(echo $OSSRH_TOKEN_USERNAME)

          ./gradlew --console=plain publish --info
      - store_artifacts:
          path: ./build/libs
          destination: spark-extension-entrypoint-artifacts
      - save_cache:
          key: v1-release-spark-extension-spark-extension-entrypoint-{{ checksum "/tmp/checksum.txt" }}
          paths:
            - ~/.m2

  integration-test-databricks-integration-spark:
    parameters:
      spark-version:
        type: string
    working_directory: ~/openlineage/integration/spark
    machine:
      image: ubuntu-2404:current
    resource_class: large
    environment:
      TESTCONTAINERS_RYUK_DISABLED: "true"
      JDK11_HOME: /usr/lib/jvm/java-11-openjdk-amd64
    steps:
      - *checkout_project_root
      - when:
          condition:
            or:
              - equal: [ enabled, << pipeline.parameters.databricks-test >> ]
              - equal: [ active, << pipeline.parameters.nightly-run >> ]
          steps:
            - run:
                name: Generate cache key
                command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
            - restore_cache:
                keys:
                  - v1-integration-spark-{{ checksum "/tmp/checksum.txt" }}
            - run:
                name: Java version Variable
                command: |
                  JAVA=8
                  JAVA8_HOME='/usr/lib/jvm/java-8-openjdk-amd64'

                  echo 'export JAVA17_HOME=/usr/lib/jvm/java-17-openjdk-amd64' >> "$BASH_ENV"
                  echo 'export JAVA_BIN='$([ "$JAVA" = "17" ] && echo "$JAVA17_HOME/bin/java" || echo "$JAVA8_HOME/jre/bin/java") >> "$BASH_ENV"
                  echo 'export JAVAC_BIN='$([ "$JAVA" = "17" ] && echo "$JAVA17_HOME/bin/javac" || echo "$JAVA8_HOME/bin/javac") >> "$BASH_ENV"
                  echo "${JAVA}"
                  echo "${JAVA_BIN}"
                  echo "${JAVAC_BIN}"
            - attach_workspace:
                at: ~/
            - run: |
                sudo update-alternatives --set java ${JAVA_BIN}
                sudo update-alternatives --set javac ${JAVAC_BIN}
            - run: ./gradlew --console=plain shadowJar -x test
            - run: ./gradlew --no-daemon --console=plain databricksIntegrationTest -x test   -Pspark.version=<< parameters.spark-version >> -PdatabricksHost=$DATABRICKS_HOST -PdatabricksToken=$DATABRICKS_TOKEN
            - store_test_results:
                path: app/build/test-results/databricksIntegrationTest
            - store_artifacts:
                path: app/build/reports/tests/databricksIntegrationTest
                destination: test-report
            - store_artifacts:
                path: app/build/cluster-log4j.log
                destination: cluster-log4j.log
            - save_cache:
                key: v1-databricks-integration-spark-{{ checksum "/tmp/checksum.txt" }}
                paths:
                  - ~/.gradle

  configurable-integration-test-spark:
    working_directory: ~/openlineage/
    machine:
      image: ubuntu-2404:current
    resource_class: large
    steps:
      - *checkout_project_root
      - when:
          condition:
            equal: [ active, << pipeline.parameters.nightly-run >> ]
          steps:
            - restore_cache:
                keys:
                  - v1-configurable-integration-test
            - set_java_17
            - run: ./integration/spark/cli/configurable-test.sh --spark ./integration/spark/cli/spark-conf.yml --test ./integration/spark/cli/tests
            - run: ./integration/spark/cli/configurable-test.sh --spark ./integration/spark/cli/spark-conf-docker.yml --test ./integration/spark/cli/tests
            - store_artifacts:
                path: integration/spark/cli/runs
                destination: test-report
            - save_cache:
                key: configurable-integration-test
                paths:
                  - ~/.gradle

  jar-verification-spark:
    working_directory: ~/openlineage/integration/spark
    machine:
      image: ubuntu-2404:current
    resource_class: medium
    environment:
      TESTCONTAINERS_RYUK_DISABLED: "true"
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - restore_cache:
          keys:
            - v1-integration-spark-{{ checksum "/tmp/checksum.txt" }}
      - set_java_17
      - attach_workspace:
          at: ~/
      - run: ./gradlew --no-daemon --console=plain clean jarVerification -Pscala.binary.version=2.12 -Pjava.compile.home=${JAVA17_HOME}
      - run: ./gradlew --no-daemon --console=plain clean jarVerification -Pscala.binary.version=2.13 -Pjava.compile.home=${JAVA17_HOME}

  slack-notify:
    docker:
      - image: 'cimg/base:stable'
    steps:
      - *checkout_project_root
      - when:
          condition:
            equal: [ active, << pipeline.parameters.nightly-run >> ]
          steps:
            - slack/notify:
                event: pass
                template: basic_success_1
            - slack/notify:
                event: fail
                template: basic_fail_1

# FLINK

  release-integration-flink:
    working_directory: ~/openlineage/integration/flink
    docker:
      - image: cimg/openjdk:11.0
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - restore_cache:
          keys:
            - v1-release-client-java-{{ checksum "/tmp/checksum.txt" }}
      - attach_workspace:
          at: ~/
      - publish_shadow_jar
      - store_artifacts:
          path: ./build/libs
          destination: flink-client-artifacts

  integration-test-integration-flink:
    parameters:
      flink-version:
        type: string
    working_directory: ~/openlineage/integration/flink
    machine:
      image: ubuntu-2404:current
    resource_class: large
    environment:
      TESTCONTAINERS_RYUK_DISABLED: "true"
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - restore_cache:
          keys:
            - v1-integration-flink-{{ checksum "/tmp/checksum.txt" }}
      - attach_workspace:
          at: ~/
      - set_java_17
      - run: chmod -R 777 data/iceberg/db
      - run: ./gradlew --console=plain examples:stateful:build -Pflink.version=<< parameters.flink-version >>
      - run: ./gradlew --no-daemon --console=plain integrationTest --i -Pflink.version=<< parameters.flink-version >>
      - run:
          when: on_fail
          command: cat app/build/test-results/integrationTest/TEST-*.xml
      - run: ./gradlew --no-daemon --console=plain jacocoTestReport
      - store_test_results:
          path: app/build/test-results/integrationTest
      - store_artifacts:
          path: app/build/reports/tests/integrationTest
          destination: test-report
      - save_cache:
          key: v1-integration-flink-{{ checksum "/tmp/checksum.txt" }}
          paths:
            - ~/.gradle

  build-integration-flink:
    working_directory: ~/openlineage/integration/flink
    docker:
      - image: cimg/openjdk:11.0
    resource_class: large
    environment:
      TESTCONTAINERS_RYUK_DISABLED: "true"
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - restore_cache:
          keys:
            - v1-integration-flink-{{ checksum "/tmp/checksum.txt" }}
      - attach_workspace:
          at: ~/
      - publish_shadow_jar_local
      - persist_to_workspace:
          root: ~/
          paths:
            - .m2/repository/io/openlineage/openlineage-flink
            - openlineage/integration/flink/build-cache
            - openlineage/integration/flink/build/libs
      - store_artifacts:
          path: build/libs
          destination: libs

  test-integration-flink:
    parameters:
      flink-version:
        type: string
    working_directory: ~/openlineage/integration/flink
    docker:
      - image: cimg/openjdk:11.0
    resource_class: large
    environment:
      TESTCONTAINERS_RYUK_DISABLED: "true"
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - restore_cache:
          keys:
            - v1-integration-flink-{{ checksum "/tmp/checksum.txt" }}
      - attach_workspace:
          at: ~/
      - run: ./gradlew --no-daemon --console=plain --stacktrace build check -Pflink.version=<< parameters.flink-version >>
      - run:
          when: on_fail
          command: cat build/test-results/test/TEST-*.xml
      - run: ./gradlew --no-daemon --console=plain jacocoTestReport
      - run: ./gradlew --console=plain javadoc
      - store_test_results:
          path: app/build/test-results/test
      - store_artifacts:
          path: app/build/reports/tests/test
          destination: test-report
      - save_cache:
          key: v1-integration-flink-{{ checksum "/tmp/checksum.txt" }}
          paths:
            - ~/.gradle

  build-proxy-fluentd:
    working_directory: ~/openlineage/proxy/fluentd
    docker:
      - image: cimg/ruby:3.2
    steps:
      - *checkout_project_root
      - run: bundle install
      - run: bundle exec rake test

  build-proxy-backend:
    working_directory: ~/openlineage/proxy/backend
    docker:
      - image: cimg/openjdk:17.0
    steps:
      - *checkout_project_root
      - run:
          name: Generate cache key
          command: ./../../.circleci/checksum.sh /tmp/checksum.txt $CIRCLE_BRANCH
      - restore_cache:
          keys:
            - v1-proxy-{{ checksum "/tmp/checksum.txt" }}
      - run: ./gradlew --no-daemon --console=plain --stacktrace build
      - run: ./gradlew --no-daemon --console=plain jacocoTestReport
      - run: bash <(curl -s https://codecov.io/bash)
      - store_test_results:
          path: proxy/build/test-results/test
      - store_artifacts:
          path: build/reports/tests/test
          destination: test-report
      - save_cache:
          key: v1-proxy-{{ checksum "/tmp/checksum.txt" }}
          paths:
            - ~/.gradle

  build-image-proxy-backend:
    working_directory: ~/openlineage/proxy/backend
    machine:
      image: ubuntu-2404:current
    steps:
      - *checkout_project_root
      - run: docker build --no-cache --tag "openlineage/proxy:${CIRCLE_SHA1}" .
      - run: docker save -o proxy.tar "openlineage/proxy:${CIRCLE_SHA1}"
      - store_artifacts:
          path: proxy.tar

  release-proxy-backend:
    working_directory: ~/openlineage/proxy/backend
    docker:
      - image: cimg/openjdk:17.0
    steps:
      - *checkout_project_root
      - run: |
          # Get, then decode the GPG private key used to sign *.jar
          export ORG_GRADLE_PROJECT_signingKey=$(echo $GPG_SIGNING_KEY | base64 -d)
          export RELEASE_PASSWORD=$(echo $OSSRH_TOKEN_PASSWORD)
          export RELEASE_USERNAME=$(echo $OSSRH_TOKEN_USERNAME)

          # publish jar to maven local so it can be found by dependents
          ./gradlew --info --console=plain publishToMavenLocal

          # Publish *.jar
          ./gradlew --info --console=plain publish

  release-docker-proxy-backend:
    working_directory: ~/openlineage/proxy/backend
    machine:
      image: ubuntu-2404:current
    steps:
      - *checkout_project_root
      - run: |
          ./docker/login.sh
          if [ -n "$CIRCLE_TAG" ]; then
            ./docker/build-and-push-proxy.sh $CIRCLE_TAG
          fi
  run-pre-commit:
    # this job run pre-commit for Python client only
    # add dependency to other files when pre-commit runs related checks
    working_directory: ~/openlineage
    docker:
      - image: cimg/python:3.8
    steps:
      - *checkout_project_root
      - restore_cache:
          keys:
          - v1.2-precommit-deps-{{ checksum ".pre-commit-config.yaml" }}

      - run:
          name: Install Dependencies
          command: |
            python3.8 -m venv venv
            . venv/bin/activate
            pip3 install pre-commit
            # Install the hooks now so that they'll be cached
            pre-commit install-hooks
      - save_cache:
          paths:
            - ~/.cache/pre-commit
          key: v1.2-precommit-deps-{{ checksum ".pre-commit-config.yaml" }}

      - run:
          name: Run pre-commit
          command: |
            . venv/bin/activate
            SKIP= && [ -n "${CI}" ] && export SKIP="pmd"
            pre-commit run --show-diff-on-failure --all-files

  build-website:
    # Build Openlineage website to make sure npm packages match
    working_directory: ~/openlineage/website
    docker:
      - image: cimg/node:22.7.0
    resource_class: large
    steps:
      - *checkout_project_root
      - run:
          name: Install Dependencies
          command: |
            yarn install --frozen-lockfile
            yarn build

  always_run:
    machine:
      image: ubuntu-2404:current
    steps:
      - run: echo "This steps always run."

  workflow_complete:
    working_directory: ~/openlineage
    machine:
      image: ubuntu-2404:current
    steps:
      - run: echo "Complete"
